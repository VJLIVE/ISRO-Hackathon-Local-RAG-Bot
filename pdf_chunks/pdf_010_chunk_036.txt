form of P(.). However, the choice of a regression model is quite subjective, and it is difficult to ensure that a particular regression model provides the best possible explanation to the variance in a data set. This has inspired the researchers to look for more objective data fitting approaches like genetic algorithm (GA). A genetic algorithm is programmed to approximate the equation, in symbolic form, that best describes the relationship between independent and dependent parameters. The genetic algorithm considers an initial population of potential solutions, which is subjected to an evolutionary process, by selecting those equations (individuals) that best fit the data. The strongest strings (made up from a combination of variables, real numbers, and arithmetic operators) of choose a mate for reproduction whereas the weaker strings become extinct. The newly generated population is subjected to mutations that change fractions of information. The evolutionary steps are repeated with the new generation. The process ends after a number of generations a priori determined by the user. The procedural details of genetic algorithm can be found in Szpiro (1997), Alvarez et al., (2000) and Singh et al (2006). A brief description of genetic algorithm is as follows. First, for a desired function x (e.g. in Eq.-6), a set of candidate equations for P(.) is randomly generated. An equation is stored in the computer as a set of characters that define the independent variables, a, b,c,d,e.. etc. in Eq. (6), and four elementary arithmetic operators (+,-,x, and /). A criterion that measures how well the equation strings perform on a training set of the data is its fitness to the data, defined as sum of the squared differences between data and independent parameter derived from the equation string. The strongest individuals (equations with best fits) are then selected to exchange parts of the